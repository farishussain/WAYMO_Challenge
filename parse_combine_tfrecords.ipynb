{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: uncompressed_tf_example_testing_testing_tfexample.tfrecord-00001-of-00150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample trajectory verification:\n",
      "History last 3 points:\n",
      "[[11806.617  9539.784]\n",
      " [11805.597  9539.777]\n",
      " [11804.558  9539.772]]\n",
      "\n",
      "Future first 3 points:\n",
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [-1. -1.]]\n",
      "Gap between history and future: 15186.3134765625\n",
      "Trajectory is continuous: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "290it [00:00, 358.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_tfrecord(record_bytes):\n",
    "    \"\"\"Parse TFRecord using the correct feature description.\"\"\"\n",
    "    \n",
    "    feature_description = {\n",
    "        # State features for 128 agents\n",
    "        \"state/id\": tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "        \"state/type\": tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "        \"state/is_sdc\": tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "        \"state/tracks_to_predict\": tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "        \n",
    "        # Current state (shape: [128, 1])\n",
    "        \"state/current/x\": tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "        \"state/current/y\": tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "        \"state/current/bbox_yaw\": tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "        \"state/current/valid\": tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
    "        \"state/current/width\": tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "        \"state/current/length\": tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "        \n",
    "        # Past state (shape: [128, 10])\n",
    "        \"state/past/x\": tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "        \"state/past/y\": tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "        \"state/past/bbox_yaw\": tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "        \"state/past/valid\": tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
    "        \n",
    "        # Future state (shape: [128, 80])\n",
    "        \"state/future/x\": tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "        \"state/future/y\": tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "        \"state/future/bbox_yaw\": tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "        \"state/future/valid\": tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
    "        \n",
    "        # Scenario ID\n",
    "        \"scenario/id\": tf.io.FixedLenFeature([1], tf.string, default_value=None),\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(record_bytes, feature_description)\n",
    "\n",
    "def process_trajectories(tfrecord_path, output_path, max_samples=None):\n",
    "    \"\"\"Process TFRecord file and save as NPZ.\"\"\"\n",
    "    \n",
    "    # Create TFRecord dataset\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    \n",
    "    # Lists to store all scenes\n",
    "    all_scenes = []\n",
    "    \n",
    "    # Process each example (scene)\n",
    "    for i, record_bytes in tqdm(enumerate(dataset)):\n",
    "        if max_samples and i >= max_samples:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            # Parse the record\n",
    "            example = parse_tfrecord(record_bytes)\n",
    "            \n",
    "            # Process each agent in the scene\n",
    "            n_agents = 128  # Fixed size from your feature description\n",
    "            \n",
    "            # Combine past and current for history\n",
    "            history_x = np.concatenate([\n",
    "                example['state/past/x'].numpy(),\n",
    "                example['state/current/x'].numpy()\n",
    "            ], axis=1)  # Shape: [128, 11]\n",
    "            \n",
    "            history_y = np.concatenate([\n",
    "                example['state/past/y'].numpy(),\n",
    "                example['state/current/y'].numpy()\n",
    "            ], axis=1)  # Shape: [128, 11]\n",
    "            \n",
    "            history_valid = np.concatenate([\n",
    "                example['state/past/valid'].numpy(),\n",
    "                example['state/current/valid'].numpy()\n",
    "            ], axis=1)  # Shape: [128, 11]\n",
    "            \n",
    "            # Get future trajectories\n",
    "            future_x = example['state/future/x'].numpy()  # Shape: [128, 80]\n",
    "            future_y = example['state/future/y'].numpy()  # Shape: [128, 80]\n",
    "            future_valid = example['state/future/valid'].numpy()  # Shape: [128, 80]\n",
    "            \n",
    "            # Create scene data\n",
    "            scene_data = {\n",
    "                'file_name': os.path.basename(tfrecord_path),\n",
    "                'scenario_id': example['scenario/id'].numpy()[0].decode(),\n",
    "                'agent_id': example['state/id'].numpy(),\n",
    "                'agent_type': example['state/type'].numpy(),\n",
    "                'agent_valid': example['state/current/valid'].numpy()[:, 0],\n",
    "                'width': example['state/current/width'].numpy()[:, 0],\n",
    "                'length': example['state/current/length'].numpy()[:, 0],\n",
    "                'history/xy': np.stack([history_x, history_y], axis=2),  # Shape: [128, 11, 2]\n",
    "                'history/yaw': np.concatenate([\n",
    "                    example['state/past/bbox_yaw'].numpy(),\n",
    "                    example['state/current/bbox_yaw'].numpy()\n",
    "                ], axis=1),\n",
    "                'history/valid': history_valid,\n",
    "                'future/xy': np.stack([future_x, future_y], axis=2),  # Shape: [128, 80, 2]\n",
    "                'future/yaw': example['state/future/bbox_yaw'].numpy(),\n",
    "                'future/valid': future_valid\n",
    "            }\n",
    "            \n",
    "            # Save individual scene\n",
    "            np.savez_compressed(output_path, **scene_data)\n",
    "            print(f\"\\nProcessed data saved to {output_path}\")\n",
    "            print(f\"Number of agents: {n_agents}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing record {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "def verify_npz_data(npz_path):\n",
    "    \"\"\"Verify the processed NPZ file.\"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    print(\"\\nData Verification:\")\n",
    "    print(\"==================\")\n",
    "    \n",
    "    # Print shapes\n",
    "    for key in data.files:\n",
    "        print(f\"{key}: {data[key].shape}\")\n",
    "        \n",
    "        # Print sample values for key fields\n",
    "        if key in ['history/xy', 'future/xy']:\n",
    "            print(f\"\\nSample {key} values (first agent, first 5 timesteps):\")\n",
    "            print(data[key][0, :5])\n",
    "\n",
    "\n",
    "def process_multiple_tfrecords(tfrecord_paths, output_path):\n",
    "    \"\"\"Process multiple TFRecord files and combine into one NPZ.\"\"\"\n",
    "    \n",
    "    combined_data = None\n",
    "    \n",
    "    for tfrecord_path in tfrecord_paths:\n",
    "        dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "        print(f\"\\nProcessing: {tfrecord_path}\")\n",
    "        \n",
    "        for i, record_bytes in tqdm(enumerate(dataset)):\n",
    "            try:\n",
    "                example = parse_tfrecord(record_bytes)\n",
    "                \n",
    "                # Create scene data\n",
    "                history_x = np.concatenate([\n",
    "                    example['state/past/x'].numpy(),\n",
    "                    example['state/current/x'].numpy()\n",
    "                ], axis=1)\n",
    "                \n",
    "                history_y = np.concatenate([\n",
    "                    example['state/past/y'].numpy(),\n",
    "                    example['state/current/y'].numpy()\n",
    "                ], axis=1)\n",
    "                \n",
    "                history_valid = np.concatenate([\n",
    "                    example['state/past/valid'].numpy(),\n",
    "                    example['state/current/valid'].numpy()\n",
    "                ], axis=1)\n",
    "                \n",
    "                scene_data = {\n",
    "                    'file_name': os.path.basename(tfrecord_path),\n",
    "                    'scenario_id': example['scenario/id'].numpy()[0].decode(),\n",
    "                    'agent_id': example['state/id'].numpy(),\n",
    "                    'agent_type': example['state/type'].numpy(),\n",
    "                    'agent_valid': example['state/current/valid'].numpy()[:, 0],\n",
    "                    'width': example['state/current/width'].numpy()[:, 0],\n",
    "                    'length': example['state/current/length'].numpy()[:, 0],\n",
    "                    'history/xy': np.stack([history_x, history_y], axis=2),\n",
    "                    'history/yaw': np.concatenate([\n",
    "                        example['state/past/bbox_yaw'].numpy(),\n",
    "                        example['state/current/bbox_yaw'].numpy()\n",
    "                    ], axis=1),\n",
    "                    'history/valid': history_valid,\n",
    "                    'future/xy': np.stack([\n",
    "                        example['state/future/x'].numpy(),\n",
    "                        example['state/future/y'].numpy()\n",
    "                    ], axis=2),\n",
    "                    'future/yaw': example['state/future/bbox_yaw'].numpy(),\n",
    "                    'future/valid': example['state/future/valid'].numpy()\n",
    "                }\n",
    "                \n",
    "                # For the first scene, initialize the combined data\n",
    "                if combined_data is None:\n",
    "                    combined_data = {k: [] for k in scene_data.keys()}\n",
    "                \n",
    "                # Append data\n",
    "                for key in combined_data:\n",
    "                    combined_data[key].append(scene_data[key])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing record {i} from {tfrecord_path}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Convert lists to arrays\n",
    "    final_data = {}\n",
    "    for key in combined_data:\n",
    "        if combined_data[key]:  # Check if list is not empty\n",
    "            try:\n",
    "                final_data[key] = np.concatenate(combined_data[key], axis=0)\n",
    "            except:\n",
    "                final_data[key] = np.array(combined_data[key])\n",
    "    \n",
    "    # Save combined data\n",
    "    np.savez_compressed(output_path, **final_data)\n",
    "    print(f\"\\nSaved combined data to: {output_path}\")\n",
    "    \n",
    "    # Print data shapes\n",
    "    print(\"\\nFinal data shapes:\")\n",
    "    for key, value in final_data.items():\n",
    "        print(f\"{key}: {value.shape}\")\n",
    "\n",
    "def verify_trajectory_continuity(history_xy, future_xy, history_valid, future_valid):\n",
    "    \"\"\"Verify that trajectories are continuous at the transition point.\"\"\"\n",
    "    # Check last point of history matches first point of future\n",
    "    last_history = history_xy[history_valid][-1]\n",
    "    first_future = future_xy[future_valid][0]\n",
    "    \n",
    "    diff = np.linalg.norm(last_history - first_future)\n",
    "    print(f\"Gap between history and future: {diff}\")\n",
    "    return diff < 1.0  # Threshold for acceptable difference\n",
    "\n",
    "def process_trajectories(tfrecord_path, output_path, max_samples=None):\n",
    "    \"\"\"Process TFRecord file and save as NPZ with verification.\"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    \n",
    "    for i, record_bytes in tqdm(enumerate(dataset)):\n",
    "        try:\n",
    "            example = parse_tfrecord(record_bytes)\n",
    "            \n",
    "            # Combine past and current for history\n",
    "            history_x = np.concatenate([\n",
    "                example['state/past/x'].numpy(),\n",
    "                example['state/current/x'].numpy()\n",
    "            ], axis=1)\n",
    "            \n",
    "            history_y = np.concatenate([\n",
    "                example['state/past/y'].numpy(),\n",
    "                example['state/current/y'].numpy()\n",
    "            ], axis=1)\n",
    "            \n",
    "            history_xy = np.stack([history_x, history_y], axis=2)\n",
    "            future_xy = np.stack([\n",
    "                example['state/future/x'].numpy(),\n",
    "                example['state/future/y'].numpy()\n",
    "            ], axis=2)\n",
    "            \n",
    "            # Print sample trajectories for verification\n",
    "            if i == 0:  # First example\n",
    "                print(\"\\nSample trajectory verification:\")\n",
    "                print(\"History last 3 points:\")\n",
    "                print(history_xy[0, -3:])\n",
    "                print(\"\\nFuture first 3 points:\")\n",
    "                print(future_xy[0, :3])\n",
    "                \n",
    "                # Verify continuity\n",
    "                history_valid = np.concatenate([\n",
    "                    example['state/past/valid'].numpy(),\n",
    "                    example['state/current/valid'].numpy()\n",
    "                ], axis=1)\n",
    "                future_valid = example['state/future/valid'].numpy()\n",
    "                \n",
    "                is_continuous = verify_trajectory_continuity(\n",
    "                    history_xy[0], future_xy[0],\n",
    "                    history_valid[0], future_valid[0]\n",
    "                )\n",
    "                print(f\"Trajectory is continuous: {is_continuous}\")\n",
    "            \n",
    "            # Create scene data dictionary\n",
    "            scene_data = {\n",
    "                'file_name': os.path.basename(tfrecord_path),\n",
    "                'scenario_id': example['scenario/id'].numpy()[0].decode(),\n",
    "                'agent_id': example['state/id'].numpy(),\n",
    "                'agent_type': example['state/type'].numpy(),\n",
    "                'agent_valid': example['state/current/valid'].numpy()[:, 0],\n",
    "                'width': example['state/current/width'].numpy()[:, 0],\n",
    "                'length': example['state/current/length'].numpy()[:, 0],\n",
    "                'history/xy': history_xy,\n",
    "                'history/yaw': np.concatenate([\n",
    "                    example['state/past/bbox_yaw'].numpy(),\n",
    "                    example['state/current/bbox_yaw'].numpy()\n",
    "                ], axis=1),\n",
    "                'history/valid': history_valid,\n",
    "                'future/xy': future_xy,\n",
    "                'future/yaw': example['state/future/bbox_yaw'].numpy(),\n",
    "                'future/valid': future_valid\n",
    "            }\n",
    "            \n",
    "            np.savez_compressed(output_path, **scene_data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing record {i}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "def main():\n",
    "    tfrecord_paths = [\n",
    "        #\"uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000\",\n",
    "        #\"uncompressed_tf_example_training_training_tfexample.tfrecord-00010-of-01000\",\n",
    "         \"uncompressed_tf_example_testing_testing_tfexample.tfrecord-00001-of-00150\"\n",
    "    ]\n",
    "    \n",
    "    output_dir = \"processed_data_testing\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for tfrecord_path in tfrecord_paths:\n",
    "        output_path = os.path.join(output_dir, \n",
    "                                 f\"processed_{os.path.basename(tfrecord_path)}.npz\")\n",
    "        print(f\"\\nProcessing: {tfrecord_path}\")\n",
    "        process_trajectories(tfrecord_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
